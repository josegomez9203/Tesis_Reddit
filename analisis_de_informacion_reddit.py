# -*- coding: utf-8 -*-
"""Analisis de informacion Reddit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oKManfnUXtzTSePKu-16nK1oDfgx3ANL

Analisis de informaci칩n, se maneja e interpreta la informaci칩n generada de Reddit.
Definir la ruta "location" donde se encuentra la informaci칩n de las noticias necesarias para hacer el an치lisis.
"""

location = "/home/josegomez/"

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd
import matplotlib
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import datetime as dt
# %matplotlib inline 
from wordcloud import WordCloud, STOPWORDS
from nltk.sentiment import SentimentIntensityAnalyzer
from textblob import TextBlob
from collections import Counter
import re
import string
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from nltk.sentiment.vader import SentimentIntensityAnalyzer as vad
from sklearn import preprocessing

import plotly.graph_objects as go
import spacy

data = pd.read_csv(location +"data/WallStreetbets.csv")
data_y = pd.read_csv(location +"data/Finance/Yahoo_GME.csv")
del data['Unnamed: 0']

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
 
pylab.rcParams['figure.figsize'] = (15, 9)   # Change the size of plots

x1 = [dt.datetime.strptime(d, "%Y-%m-%d").date() for d in data_y["Date"]]
y11= data_y["Adj Close"]
y1 = preprocessing.scale(data_y["Adj Close"])

plt.title("Precio de Cierre de GME de Enero 2020 a Enero 2022 ")
plt.xlabel("Dia")
plt.xticks(rotation=45)
plt.ylabel("Precio")
plt.plot_date(x1,y11,c="blue",ls="--" ,lw=2)
plt.show()

fig = go.Figure(data=[go.Candlestick(x=data_y['Date'],
                open=data_y['Open'],
                high=data_y['High'],
                low=data_y['Low'],
                close=data_y['Close'])])

fig.show()

data.describe().transpose()

authors_count = data[['Title','Author']].groupby('Author').count() 
#Put them in order from highest to lowest
authors_count = authors_count.sort_values(by='Title', ascending=False)
authors_count.head(10)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
sub_aut = data['Author'].value_counts()
sub_aut = sub_aut[sub_aut >= 200]
sub_aut.plot(kind='pie', figsize=(10,10))

data['Publish Date'] = data['Publish Date'].apply(lambda x: x.split(' ')[0])
#print(data.groupby(['Publish Date']).size().sort_values())
post_count = data[['Publish Date','Title']].groupby('Publish Date').count() 
post_count = post_count.sort_values(by='Title', ascending=False)
post_count.head(10)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
sub_date = data['Publish Date'].value_counts().sort_index()
sub_date.plot(kind='line', figsize=(10,10))

y=data['Publish Date'].unique()
x2 = [dt.datetime.strptime(d, "%Y-%m-%d").date() for d in y]
y22 = data['Publish Date'].value_counts().sort_index()
y2 = preprocessing.scale(data['Publish Date'].value_counts().sort_index())
pylab.rcParams['figure.figsize'] = (15, 9)   # Change the size of plots
plt.title("Volumen de noticias de wallstretbets de Enero 2020 a Enero 2022 ")
plt.xlabel("Dia")
plt.xticks(rotation=45)
plt.ylabel("Volumen")
plt.plot_date(x2,y22,c="blue",ls="--" ,lw=2)
plt.show()

def clean_text(text):
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    text = re.sub(r'\s+[a-zA-Z]\s+', '', text)
    doc = nlp(text)
    return ' '.join([token.text for token in doc if not token.is_stop]) #Elimina las stopwords

nlp = spacy.blank('en')
title_data = data['Title'].apply(lambda x:clean_text(x))

data_title = pd.concat([data['Publish Date'],title_data], axis=1)
data_title

data_title = title_data.apply(lambda x:str(x).split())
top = Counter([item for sublist in data_title for item in sublist])
temp = pd.DataFrame(top.most_common(20))
temp.columns = ['Common_words','count']
temp.style.background_gradient(cmap='Blues')

import plotly.express as px
fig = px.bar(temp, x="count", y="Common_words", title='Palabras comunes en el texto', orientation='h', 
             width=700, height=700,color='Common_words')
fig.show()

#import spacy
#nlp = spacy.blank('en')
##data['Title'].apply(lambda x:str(x).split())
#title_data = data['Title'].apply(lambda x:clean_text(x))
#data_proc = pd.concat([data['Publish Date'],title_data], axis=1)
#data_proc['Title']  = data_proc.groupby(['Publish Date'])['Title'].transform(lambda x: ' '.join(x))
#data_proc = data_proc.drop_duplicates()
#data_proc

data_proc = pd.read_csv(location +"data/data_procesada.csv")
del data_proc['Unnamed: 0']
count_unique_words = data_proc['Title'].apply(lambda x:len(set(str(x).split())))
df_unique_words = pd.concat([data_proc['Publish Date'],count_unique_words], axis=1)
df_unique_words

y = df_unique_words['Publish Date'].unique()
x3 = [dt.datetime.strptime(d, "%Y-%m-%d").date() for d in y]
y33 = df_unique_words['Title']
y3 = preprocessing.scale(df_unique_words['Title'])
pylab.rcParams['figure.figsize'] = (15, 9)   # Change the size of plots
plt.title("Palabras unicas en noticias de wallstretbets de Enero 2020 a Enero 2022 ")
plt.xlabel("Dia")
plt.xticks(rotation=45)
plt.ylabel("Palabras Unicas")
plt.plot_date(x3,y33,c="blue",ls="--" ,lw=2)
plt.show()

pylab.rcParams['figure.figsize'] = (15, 9)   # Change the size of plots
plt.title("Noticias de wallstretbets de Enero 2020 a Enero 2022 ")
plt.xlabel("Dia")
plt.xticks(rotation=45)
plt.ylabel("Valor")
plt.plot_date(x1,y1, marker='+',c="red",ls="--" ,lw=1,label="Precio")
plt.plot_date(x2,y2, marker='x',c="green",ls="--" ,lw=1, label="Volumen")
plt.plot_date(x3,y3, marker='*',c="blue",ls="--" ,lw=1, label="Vocabulario")
plt.legend(loc="upper left")
plt.show()



